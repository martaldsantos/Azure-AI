{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic Data\n",
    "\n",
    "This notebook uses the [Synthetics Package](https://learn.microsoft.com/en-us/azure/ai-studio/how-to/generate-data-qa#install-the-synthetics-package) to create sample evaluation data for your LLM without context, using a Markdown file. It then transforms the result dictionary into a .csv file that you can use in the evaluation step of your Prompt Flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the requirements needed (bare in mind there could be some dependencies pending):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to connect to Azure OpenAI so that we can access the LLM to generate data for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.resources.client import AIClient \n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "subscription: str = \"your subscription_id\"\n",
    "resource_group: str = \"rg-name\"\n",
    "project: str = \"project-name\"\n",
    "\n",
    "ai_client = AIClient(\n",
    "    subscription_id=subscription, \n",
    "    resource_group_name=resource_group, \n",
    "    project_name=project, \n",
    "    credential=DefaultAzureCredential())\n",
    "\n",
    "aoai_connection = ai_client.get_default_aoai_connection()\n",
    "aoai_connection.set_current_environment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, we get the LLM ready to generate the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.ai.generative.synthetic.qa import QADataGenerator\n",
    "\n",
    "model_name = \"gpt-35-turbo\" \n",
    "\n",
    "model_config = dict(\n",
    "    deployment=model_name, \n",
    "    model=model_name,  \n",
    "    max_tokens=2000,\n",
    ")\n",
    "\n",
    "qa_generator = QADataGenerator(model_config=model_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we are working with a single markdown file, we are loading it into a string so it will be inputed into the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def read_md_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        content = file.read()\n",
    "    return content\n",
    "\n",
    "content = read_md_file('product_info_1.md')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us create some text. We use the generate function in QADataGenerator to generate questions based on the text. In this example, the generate function takes the following parameters:\n",
    "\n",
    "- text is your source data.\n",
    "- qa_type defines the type of question and answers to be generated.\n",
    "- num_questions is the number of question-answer pairs to be generated for the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: What is the brand of the TrailMaster X4 Tent?\n",
      "A: The brand of the TrailMaster X4 Tent is OutdoorLiving.\n",
      "Q: How many people can it accommodate?\n",
      "A: The TrailMaster X4 Tent can comfortably accommodate up to 4 people with room for their gear.\n",
      "Q: Is there a warranty on it?\n",
      "A: Yes, the TrailMaster X4 Tent comes with a 2-year limited warranty against manufacturing defects.\n",
      "Q: What accessories are included with it?\n",
      "A: The TrailMaster X4 Tent includes a rainfly, tent stakes, guy lines, and a carry bag for easy transport.\n",
      "Q: Can it be easily carried during hikes?\n",
      "A: Yes, the TrailMaster X4 Tent weighs just 12lbs, and when packed in its carry bag, it can be comfortably carried during hikes.\n",
      "Tokens used: {'completion_tokens': 243, 'prompt_tokens': 2343, 'total_tokens': 2586}\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.generative.synthetic.qa import QAType\n",
    "\n",
    "qa_type = QAType.CONVERSATION\n",
    "\n",
    "result = qa_generator.generate(text=content, qa_type=qa_type, num_questions=5)\n",
    "\n",
    "for question, answer in result[\"question_answers\"]:\n",
    "    print(f\"Q: {question}\")\n",
    "    print(f\"A: {answer}\")\n",
    "\n",
    "print(f\"Tokens used: {result['token_usage']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "# Extract question-answer pairs\n",
    "qa_pairs = [(question, answer) for question, answer in result[\"question_answers\"]]\n",
    "\n",
    "df_qa = pd.DataFrame(qa_pairs, columns=['Question', 'Answer'])\n",
    "\n",
    "df_qa.to_csv('output.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azureml_py310_sdkv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
